{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for \"Models in Pyro: From Primitive Distributions to Stochastic Functions\"\n",
    "http://pyro.ai/examples/intro_part_i.html\n",
    "\n",
    "In this workbook I go through the first example in the Pyro docs, making notes as I go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pyro\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyro programs are made up of stochastic functions, which are composed to form more complex stochastic functions, aka models. Stochastic functions can be anything that has a __call__() method, so include regular Python functions and methods.\n",
    "\n",
    "The stochastic functions in pyro.distributions are GPU-accelerated multivariate distributions built on PyTorch, so I should use these wherever possible. Like in PyMC3, custom distributions come from subclassing Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.0331\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mu = Variable(torch.zeros(1))\n",
    "sigma = Variable(torch.ones(1))\n",
    "x = dist.normal(mu, sigma)\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-1.4526\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_p_x = dist.normal.log_pdf(x, mu, sigma)\n",
    "print log_p_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyro.sample\n",
    "\n",
    "This generates a _named_ sample from a stochastic function, and appears to have the syntax:\n",
    "\n",
    "var = pyro.sample(name, fn, *args)\n",
    "\n",
    "Apparently this named-ness is somehow useful:\n",
    "\n",
    "_\"Pyroâ€™s backend uses these names to uniquely identify sample statements and change their behavior at runtime depending on how the enclosing stochastic function is being used.\"_\n",
    "\n",
    "Currently this is a little mysterious - my best guess is that this is referring to either autograd or to performing different actions based on the values passed to the function (like tt.switch does)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sunny', 86.05570220947266)\n",
      "('sunny', 52.917903900146484)\n",
      "('sunny', 75.6844253540039)\n"
     ]
    }
   ],
   "source": [
    "def weather():\n",
    "    cloudy = pyro.sample('cloudy', \n",
    "                         dist.bernoulli, \n",
    "                         Variable(torch.Tensor([0.3]))) # still need to wrap consts\n",
    "    \n",
    "    cloudy = 'cloudy' if cloudy.data[0] == 1.0 else 'sunny' # torch holds data in Tensor.data\n",
    "    \n",
    "    mean_temp = {'cloudy': [55.0], 'sunny': [75.0]}[cloudy]\n",
    "    sigma_temp = {'cloudy': [10.0], 'sunny': [15.0]}[cloudy]\n",
    "    \n",
    "    temp = pyro.sample('temp', dist.normal,\n",
    "                       Variable(torch.Tensor(mean_temp)),\n",
    "                       Variable(torch.Tensor(sigma_temp)))\n",
    "    return cloudy, temp.data[0]\n",
    "\n",
    "for _ in range(3):\n",
    "    print weather()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here the variable name 'cloudy' is not being used, and it's just a coincidence that the pyro.sample variable is called 'cloudy'; it still works fine if you call it something else.\n",
    "\n",
    "The following line converts integer value from Bernoulli -> string to go into the relevant dicts defined on the following lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic functions\n",
    "\n",
    "Pyro can work with conventional Python logic in a really nice way, for instance in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def geometric(p, t=None):\n",
    "    if t is None:\n",
    "        t = 0\n",
    "    x = pyro.sample(\"x_{}\".format(t), dist.bernoulli, p)\n",
    "    if torch.equal(x.data, torch.zeros(1)):\n",
    "        return x\n",
    "    else:\n",
    "        return x + geometric(p, t+1)\n",
    "\n",
    "print(geometric(Variable(torch.Tensor([0.9]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like it should be computationally expensive, but that depends how much cleverness/optimisation Torch and Pyro are doing out of sight. \n",
    "\n",
    "Using conventional Python functions seems more lightweight/easy to work with than needing to define Ops, though I don't know how much extra machinery will be needed when gradients enter the picture, or if heavy numerics are required (e.g. ODE solutions). I will be very impressed if either of these are easy to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.autograd.variable.Variable'>\n",
      "-0.214653119445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.4611\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normal_product(mu, sigma):\n",
    "    z1 = pyro.sample(\"z1\", dist.normal, mu, sigma)\n",
    "    z2 = pyro.sample(\"z2\", dist.normal, mu, sigma)\n",
    "    y = z1 * z2\n",
    "    print type(y)\n",
    "    print mu.data[0]\n",
    "    return y\n",
    "\n",
    "def make_normal_normal():\n",
    "    mu_latent = pyro.sample(\"mu_latent\", dist.normal,\n",
    "                            Variable(torch.zeros(1)),\n",
    "                            Variable(torch.ones(1)))\n",
    "    fn = lambda sigma: normal_product(mu_latent, sigma)\n",
    "    return fn\n",
    "\n",
    "make_normal_normal()(Variable(torch.ones(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So so far we've seen that:\n",
    "- Pyro uses Torch as the computational framework\n",
    "- We can define normal Python functions to do our sampling (nice!)\n",
    "- Calling these functions with pyro.sample generates named Torch Variables\n",
    "- In some currently vague way this will be essential for what we want Pyro to do, and we need to take care to pass pyro.sample unique names whenever it's called (e.g. by using \"mystring\\_{}\".format())\n",
    "- This has something to do with specifying the joint distribution of the model - is it building a Bayes net?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
